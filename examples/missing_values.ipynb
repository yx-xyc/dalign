{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values Function Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file to DataFrame to show example\n",
    "df=pd.read_csv('../../data/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## missing_val_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_val_info(df):\n",
    "    \n",
    "    \"\"\"    \n",
    "    Show the DataFrame with the column has missing value as index and the missing counts \n",
    "    and missing percent of each column.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        The DataFrame to report missing values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    res : DataFrame\n",
    "        The DataFrame that reports missing values.\n",
    "    \"\"\"\n",
    "    \n",
    "    res = pd.DataFrame(np.sum(df.isnull())[np.sum(df.isnull())!=0], columns=[\"Missing\"])\n",
    "    res['Missing Percent %'] = res['Missing']/df.shape[0]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing</th>\n",
       "      <th>Missing Percent %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>entity_country</th>\n",
       "      <td>26</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity_exch_code</th>\n",
       "      <td>40</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity_industry</th>\n",
       "      <td>26</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity_region</th>\n",
       "      <td>26</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity_sector</th>\n",
       "      <td>22</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Missing  Missing Percent %\n",
       "entity_country         26           0.000013\n",
       "entity_exch_code       40           0.000020\n",
       "entity_industry        26           0.000013\n",
       "entity_region          26           0.000013\n",
       "entity_sector          22           0.000011"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_val_info(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## handle_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing(df, method=\"drop\"):\n",
    "\n",
    "    \"\"\"\n",
    "    Handle the missing value in the DataFrame with the method indicated. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        The DataFrame contains NaN valuess\n",
    "    method : str\n",
    "        The method to handle NaN values. The set of potential methods is:\n",
    "        'drop' : drop all the rows that contains NaN value.\n",
    "        'forward' : replace NaN value with the last value in the column.\n",
    "        'backward' : replace NaN value with the next value in the column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "     : DataFrame\n",
    "        The DataFrame with all NaN values handled.\n",
    "    \"\"\"\n",
    "\n",
    "    if method==\"drop\":\n",
    "        return df.dropna()\n",
    "    elif method==\"forward\":\n",
    "        return df.fillna(method='ffill')\n",
    "    elif method==\"backward\":\n",
    "        return df.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[5,3] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     NYSE\n",
       "1                     NYSE\n",
       "2                     NYSE\n",
       "3    London Stock Exchange\n",
       "4    London Stock Exchange\n",
       "5                      NaN\n",
       "6                     NYSE\n",
       "7                     NYSE\n",
       "8                     NYSE\n",
       "Name: entity_exchange, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0:9,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     NYSE\n",
       "1                     NYSE\n",
       "2                     NYSE\n",
       "3    London Stock Exchange\n",
       "4    London Stock Exchange\n",
       "6                     NYSE\n",
       "7                     NYSE\n",
       "8                     NYSE\n",
       "9                     NYSE\n",
       "Name: entity_exchange, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handle_missing(df, method=\"drop\").iloc[0:9,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     NYSE\n",
       "1                     NYSE\n",
       "2                     NYSE\n",
       "3    London Stock Exchange\n",
       "4    London Stock Exchange\n",
       "5    London Stock Exchange\n",
       "6                     NYSE\n",
       "7                     NYSE\n",
       "8                     NYSE\n",
       "Name: entity_exchange, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handle_missing(df, method=\"forward\").iloc[0:9,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     NYSE\n",
       "1                     NYSE\n",
       "2                     NYSE\n",
       "3    London Stock Exchange\n",
       "4    London Stock Exchange\n",
       "5                     NYSE\n",
       "6                     NYSE\n",
       "7                     NYSE\n",
       "8                     NYSE\n",
       "Name: entity_exchange, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handle_missing(df, method=\"backward\").iloc[0:9,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute(df, column, method=\"mean\"):\n",
    "\n",
    "    \"\"\"    \n",
    "    Given a numeric column from a data frame, impute all the NaN value in the column with the indicated method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        The DataFrame contains numeric column with NaN values.\n",
    "    column : str\n",
    "        The column name of the numerical column to impute.\n",
    "    method : str\n",
    "        The method to impute the NaN value to. The set of potential methods is:\n",
    "        'mean' : Replace all the NaN value with the mean value of the column.\n",
    "        'median' : Replace all the NaN value with the median value of the column.\n",
    "        'mood' : Replace all the NaN value with the mood value of the column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "     : Series\n",
    "        The Series with all the NaN values imputed.\n",
    "    \"\"\"\n",
    "\n",
    "    if method==\"mean\":\n",
    "        return df[column].replace(np.nan, np.nanmean(df[column]))\n",
    "    elif method==\"median\":\n",
    "        return df[column].replace(np.nan, np.nanmedian(df[column]))\n",
    "    elif method==\"mood\":\n",
    "        return df[column].replace(np.nan, df[column].value_counts().index[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1,\"entity_relevance\"] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          100.0\n",
       "1            NaN\n",
       "2          100.0\n",
       "3           90.0\n",
       "4           90.0\n",
       "           ...  \n",
       "2038199    100.0\n",
       "2038200    100.0\n",
       "2038201    100.0\n",
       "2038202     90.0\n",
       "2038203    100.0\n",
       "Name: entity_relevance, Length: 2038204, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"entity_relevance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          100.000000\n",
       "1           90.665062\n",
       "2          100.000000\n",
       "3           90.000000\n",
       "4           90.000000\n",
       "              ...    \n",
       "2038199    100.000000\n",
       "2038200    100.000000\n",
       "2038201    100.000000\n",
       "2038202     90.000000\n",
       "2038203    100.000000\n",
       "Name: entity_relevance, Length: 2038204, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impute(df, \"entity_relevance\", method=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          100.0\n",
       "1          100.0\n",
       "2          100.0\n",
       "3           90.0\n",
       "4           90.0\n",
       "           ...  \n",
       "2038199    100.0\n",
       "2038200    100.0\n",
       "2038201    100.0\n",
       "2038202     90.0\n",
       "2038203    100.0\n",
       "Name: entity_relevance, Length: 2038204, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impute(df, \"entity_relevance\", method=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          100.0\n",
       "1          100.0\n",
       "2          100.0\n",
       "3           90.0\n",
       "4           90.0\n",
       "           ...  \n",
       "2038199    100.0\n",
       "2038200    100.0\n",
       "2038201    100.0\n",
       "2038202     90.0\n",
       "2038203    100.0\n",
       "Name: entity_relevance, Length: 2038204, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impute(df, \"entity_relevance\", method=\"mood\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rolling_impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_impute(df, column, method=\"mean\"):\n",
    "\n",
    "    \"\"\"    \n",
    "    Given a numeric column from a data frame, impute all the NaN value in the column with the indicated method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        The DataFrame contains numeric column with NaN values.\n",
    "    column : str\n",
    "        The column name of the numerical column to impute.\n",
    "    method : str\n",
    "        The method to impute the NaN value to. The set of potential methods is:\n",
    "        'mean' : Replace all the NaN value with the mean value of all the values prior to the NaN value.\n",
    "        'median' : Replace all the NaN value with the median value of all the values prior to the NaN value.\n",
    "        'mood' : Replace all the NaN value with the mood value of all the values prior to the NaN value.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "     : Series\n",
    "        The Series with all the NaN values imputed.\n",
    "    \"\"\"\n",
    "    indexes = np.where(df[column].isnull())[0]\n",
    "    if method==\"mean\":\n",
    "        indexes = np.where(df[column].isnull())[0]\n",
    "        tmps = [np.nanmean(df.loc[0:index-1, column]) for index in indexes]\n",
    "        temp_df = df.copy()\n",
    "        temp_df.loc[indexes, column] = tmps\n",
    "        return  temp_df[column]\n",
    "    elif method==\"median\":\n",
    "        indexes = np.where(df[column].isnull())[0]\n",
    "        tmps = [np.nanmedian(df.loc[0:index-1, column]) for index in indexes]\n",
    "        temp_df = df.copy()\n",
    "        temp_df.loc[indexes, column] = tmps\n",
    "        return  temp_df[column]\n",
    "    elif method==\"mood\":\n",
    "        indexes = np.where(df[column].isnull())[0]\n",
    "        tmps = [df.loc[0:index, column].value_counts().index[0] for index in indexes]\n",
    "        temp_df = df.copy()\n",
    "        temp_df.loc[indexes, column] = tmps\n",
    "        return  temp_df[column]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     100.0\n",
       "1     100.0\n",
       "2       NaN\n",
       "3      90.0\n",
       "4       NaN\n",
       "5      90.0\n",
       "6      90.0\n",
       "7       NaN\n",
       "8      90.0\n",
       "9      45.0\n",
       "10     45.0\n",
       "Name: entity_relevance, dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[2, 'entity_relevance'] = np.NaN\n",
    "df.loc[4, 'entity_relevance'] = np.NaN\n",
    "df.loc[7, 'entity_relevance'] = np.NaN\n",
    "df.loc[0:10, 'entity_relevance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100.000000\n",
       "1    100.000000\n",
       "2    100.000000\n",
       "3     90.000000\n",
       "4     96.666667\n",
       "5     90.000000\n",
       "6     90.000000\n",
       "7     94.000000\n",
       "8     90.000000\n",
       "9     45.000000\n",
       "Name: entity_relevance, dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolling_impute(df, 'entity_relevance', 'mean')[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100.0\n",
       "1    100.0\n",
       "2    100.0\n",
       "3     90.0\n",
       "4    100.0\n",
       "5     90.0\n",
       "6     90.0\n",
       "7     90.0\n",
       "8     90.0\n",
       "9     45.0\n",
       "Name: entity_relevance, dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolling_impute(df, 'entity_relevance', 'median')[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100.0\n",
       "1    100.0\n",
       "2    100.0\n",
       "3     90.0\n",
       "4    100.0\n",
       "5     90.0\n",
       "6     90.0\n",
       "7     90.0\n",
       "8     90.0\n",
       "9     45.0\n",
       "Name: entity_relevance, dtype: float64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolling_impute(df, 'entity_relevance', 'mood')[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "69d60258ffbe36d4a395cd9d8e6c4b82dbe1928097eb03db2d2550a9fd9e8bfc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
